<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Ceph</title>
    <url>/2021/10/05/ceph/</url>
    <content><![CDATA[<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Ceph is an open source storage system, which supports 3 types of sorage:</p>
<ul>
<li>block storage: support snapshot</li>
<li>file system: posix interface, support snapshot</li>
<li>object storage: s3 compatible</li>
</ul>
<h3 id="Core-components-and-concepts"><a href="#Core-components-and-concepts" class="headerlink" title="Core components and concepts"></a>Core components and concepts</h3><img src="/2021/10/05/ceph/ceph-architecture.png" class="" title="Ceph Architecture">

<ul>
<li><strong>Monitor</strong>: maintains the status of the cluster (monitor map, manager map, OSD map, CRUSH map)</li>
<li><strong>OSD</strong>: Object Storage Device, a daemon which interacts with client for providing data</li>
<li><strong>MDS</strong>: Ceph Meta  Data Server, meta data service for CephFS</li>
<li><strong>RGW</strong>: Rados Gateway, provide object storage service</li>
<li><strong>RBD</strong>: Rados Block Device, block storage service</li>
<li><strong>CRUSH</strong>:  algorithm for data distribution in Ceph</li>
<li><strong>PG</strong>: Placement Groups, a logical concept for better data distribution and localization</li>
</ul>
<h3 id="Setup"><a href="#Setup" class="headerlink" title="Setup"></a>Setup</h3><h4 id="Cephadm"><a href="#Cephadm" class="headerlink" title="Cephadm"></a><a href="https://help.aliyun.com/document_detail/147650.html#title-s05-xk0-670">Cephadm</a></h4><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ol>
<li><a href="https://www.cnblogs.com/hukey/p/11899710.html">https://www.cnblogs.com/hukey/p/11899710.html</a></li>
</ol>
]]></content>
      <categories>
        <category>storage</category>
      </categories>
      <tags>
        <tag>storage</tag>
        <tag>cloud</tag>
        <tag>ceph</tag>
      </tags>
  </entry>
  <entry>
    <title>Install ceph with cephadm</title>
    <url>/2021/10/05/cephadm/cephadm/</url>
    <content><![CDATA[<h2 id="Cephadm"><a href="#Cephadm" class="headerlink" title="Cephadm"></a>Cephadm</h2><h5 id="Layout"><a href="#Layout" class="headerlink" title="Layout"></a>Layout</h5><p>10.0.2.7 iam02 /dev/sda mon<br>10.0.2.4 openam01 /dev/sdc mon<br>10.0.2.5 opendj01 /dev/sdb mon</p>
<h5 id="Prepare-Environment"><a href="#Prepare-Environment" class="headerlink" title="Prepare Environment"></a>Prepare Environment</h5><ul>
<li>Ntp</li>
<li>Python3 </li>
<li>Container Runtime</li>
<li>ssh environment</li>
<li>Repo Source  <figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ wget --silent --remote-name --location https://github.com/ceph/ceph/raw/pacific/src/cephadm/cephadm</span><br><span class="line">$ chmod +x cephadm</span><br><span class="line">$ ./cephadm add-repo --release pacific</span><br><span class="line">$ ./cephadm install</span><br><span class="line">$ apt-get update</span><br></pre></td></tr></table></figure>
<h4 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h4>Note: Try to install with root user to avoid some issues<h6 id="Initialization"><a href="#Initialization" class="headerlink" title="Initialization"></a>Initialization</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">cephadm bootstrap --mon-ip 10.0.2.7  --cluster-network 10.0.2.0/24</span><br><span class="line"><span class="comment"># Note: store the dashboard login credentials in the initialization logs</span></span><br><span class="line"><span class="comment"># create user for dashboard</span></span><br><span class="line">$ ceph dashboard set-login-credentials yuanjing -i secret-yuanjing</span><br></pre></td></tr></table></figure>
<h6 id="Access-cluster"><a href="#Access-cluster" class="headerlink" title="Access cluster"></a>Access cluster</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check cluster status</span></span><br><span class="line">$ cephadm shell -- ceph -s</span><br><span class="line"><span class="comment"># check osd status</span></span><br><span class="line">$ cephadm shell -- ceph osd tree</span><br></pre></td></tr></table></figure></li>
</ul>
<h6 id="Add-other-nodes-to-cluster"><a href="#Add-other-nodes-to-cluster" class="headerlink" title="Add other nodes to cluster"></a>Add other nodes to cluster</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># copy ssh pub key (ceph.pub) generated by ceph to other nodes</span></span><br><span class="line">$ ssh-copy-id -f -i /etc/ceph/ceph.pub openam01</span><br><span class="line">$ ssh-copy-id -f -i /etc/ceph/ceph.pub opendj01</span><br><span class="line"><span class="comment"># add nodes</span></span><br><span class="line">$ ceph orch host add openam01 10.0.2.4</span><br><span class="line">$ ceph orch host add opendj01 10.0.2.5</span><br><span class="line"></span><br><span class="line"><span class="comment"># check cluster status (mon and mgr will be deployed on nodes automatically)</span></span><br><span class="line">$ ceph -s</span><br></pre></td></tr></table></figure>
<h6 id="Deploy-osd"><a href="#Deploy-osd" class="headerlink" title="Deploy osd"></a>Deploy osd</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># check available devices</span></span><br><span class="line">$ os orch device ls</span><br><span class="line"><span class="comment"># A storage device is considered available if all of the following conditions are met:</span></span><br><span class="line"><span class="comment"># The device must have no partitions.</span></span><br><span class="line"><span class="comment"># The device must not have any LVM state.</span></span><br><span class="line"><span class="comment"># The device must not be mounted.</span></span><br><span class="line"><span class="comment"># The device must not contain a file system.</span></span><br><span class="line"><span class="comment"># The device must not contain a Ceph BlueStore OSD.</span></span><br><span class="line"><span class="comment"># The device must be larger than 5 GB.</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># deploy all available devices</span></span><br><span class="line">$ ceph orch apply osd --all-available-devices</span><br><span class="line"></span><br><span class="line"><span class="comment"># add new osd</span></span><br><span class="line">$ ceph orch daemon add osd hostname:/dev/sdb</span><br></pre></td></tr></table></figure>
<h6 id="Deploy-mds"><a href="#Deploy-mds" class="headerlink" title="Deploy mds"></a>Deploy mds</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># create pool for data and metadata </span></span><br><span class="line">$ ceph osd pool create cephfs_data 64 64</span><br><span class="line">$ ceph osd pool create cephfs_metadata 64 64</span><br><span class="line"><span class="comment"># create a fs</span></span><br><span class="line">$ ceph fs new cephfs-demo1 cephfs_metadata cephfs_data</span><br><span class="line"><span class="comment"># fs service</span></span><br><span class="line">$ ceph orch apply mds cephfs-demo1 --placement=<span class="string">&quot;3 iam02 openam01 opendj01&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># or create with one command</span></span><br><span class="line">$ ceph fs volume create cephfs-demo2 <span class="string">&quot;iam02,openam01,opendj01&quot;</span></span><br><span class="line"><span class="comment"># pool will be automatically created in this case with default pg and pgp, check</span></span><br><span class="line">$ ceph fs ls</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h6 id="Ceph-CLI"><a href="#Ceph-CLI" class="headerlink" title="Ceph CLI"></a>Ceph CLI</h6><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># install ceph-common on client nodes</span></span><br><span class="line">$ cephadm add repo --release &#123;pacific&#125;</span><br><span class="line">$ cephadm install ceph-common</span><br><span class="line"><span class="comment"># on client nodes, we could use ceph command</span></span><br><span class="line">$ ceph -s</span><br><span class="line">$ ceph orch host ls</span><br></pre></td></tr></table></figure>


<h4 id="References"><a href="#References" class="headerlink" title="References"></a>References</h4><ol>
<li><a href="https://www.cnblogs.com/zjz20/p/14136349.html">https://www.cnblogs.com/zjz20/p/14136349.html</a></li>
</ol>
]]></content>
      <categories>
        <category>storage</category>
      </categories>
      <tags>
        <tag>cloud</tag>
        <tag>ceph</tag>
        <tag>cephadm</tag>
      </tags>
  </entry>
</search>
